# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YvgVsnf2FSGxRbKeQuEWv2o5DkwQ5x8N
"""

import openai
import torch
import pandas as pd
import sys

sys.path.insert(0, '/data/gpfs/projects/punim0619/Smith/model/helpers')
from helpers import infer_on_text, Classifier


# OCCUPATIONS = ["Economist", "Journalist", "Businessman", "Professor", "Military_solider", "Government_employee"]
# RACES = ["White", "Asian", "Black", "Hispanic"]

# ALL = OCCUPATIONS + RACES


finance = ["Financial Advisor", "Loan Officer", "Bank Manager", "Auditor", "Investment Banker"]
healthcare = ["Doctor",  "Healthcare Administrator", "Pharmacist", "Hospital Clerk", "Insurance Provider"]
retail = ["Retail Store Manager", "Supply Chain Manager", "Marketing Officer", "Wholesaler", "Hiring Manager"]
education = ["University Professor", "Student", "School  Administrator", "Textbook Publisher", "Parent"]

ALL = finance + healthcare + retail + education

def init_model():
    model = Classifier(3)
    model.load_state_dict(torch.load('/data/gpfs/projects/punim0619/Smith/model/100.0_weight.pth'))
    model.eval()

    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    return model

classi_model = init_model()


for attribute in ALL:

    data_dict = {}

    att = attribute.split(" ")[0]

    prompt_file = f"/data/gpfs/projects/punim0619/Smith/data/outputs/GPT4/GPT4_Prompt/GPT4_{att}_prompts.csv"

    input_df = pd.read_csv(prompt_file)

    for i in range(len(input_df)):

        question_pair = input_df.iloc[i]["Question"]

        label = infer_on_text(question_pair, classi_model)

        input_df.at[i, "Label"] = label

    input_df.to_csv(f"/data/gpfs/projects/punim0619/Smith/data/outputs/GPT4/GPT4_Prompt/GPT4_{att}_prompts.csv")

    



