# -*- coding: utf-8 -*-
"""classification_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kTSieSQXUswiXQYp4srdL8ePfLgo72hw
"""



#!pip install transformers

"""#Loading in Data"""
import pandas as pd
from sklearn import preprocessing
from transformers import TFAutoModel, AutoTokenizer, BertModel
from transformers import DataCollatorWithPadding, BertTokenizer, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
import tensorflow as tf
import tensorflow_hub as hub
import torch
from torch.utils.data import Dataset, DataLoader
from torch import nn, optim
import numpy as np
import torch.nn.functional as F
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import time
from sklearn.dummy import DummyClassifier
import warnings
from sklearn.exceptions import UndefinedMetricWarning
warnings.filterwarnings("ignore", category=UndefinedMetricWarning)


# df_original = pd.read_csv("/content/drive/MyDrive/Research/labelled.csv").transpose()
# df_original = df_original.reset_index()
# df_original.columns = ["Question", "Label"]

# le = preprocessing.LabelEncoder()
# df_original["Label"] = le.fit_transform(df_original["Label"])

# print(df.head(5))
# #print encoding map
#print(le.classes_)

PATH = '/data/gpfs/projects/punim0619/Smith/model'




df_doubled = pd.read_csv(f"{PATH}/output.csv")
df_doubled.drop(columns=['Unnamed: 0'], inplace=True)
#df.head(5)

df_lib_con_balanced = pd.read_csv(f"{PATH}/balanced.csv")
df_lib_con_balanced.drop(columns=['Unnamed: 0'], inplace=True)


df_all_balanced = pd.read_csv(f"{PATH}/all_balanced.csv")

df = df_all_balanced

line = "-"*20

print('\n\n')
print(df.head())
print(df.info())
print('\n\n')

"""#Init Model & Tokenizer"""

tokenizer_obj = BertTokenizer.from_pretrained("bert-base-uncased")

df_train, df_test = train_test_split(df, test_size=0.2, stratify=df['Label'])


df_test, df_val = train_test_split(df_test, test_size=0.5, stratify=df_test['Label'])

"""#Creating Dataset and DataLoader"""

#creating Dataset item
class PairDataset(Dataset):
  def __init__(self, questions, targets, tokenizer, max_len, include_raw_text=False):
    self.questions = questions
    self.targets = targets
    self.tokenizer = tokenizer
    self.max_len = max_len
    self.include_raw_text = include_raw_text

  #return length of the Dataset i.e how many items
  def __len__(self):
    return len(self.questions)

  #prep the data into the format that a model requires
  #in this case, BERT needs input_ids, attention_masks and targets
  def __getitem__(self, item):
    question = str(self.questions[item])
    target = self.targets[item]

    encoding = self.tokenizer.encode_plus(
        question,
        add_special_tokens = True,
        max_length = self.max_len,
        return_token_type_ids = False,
        return_attention_mask = True,
        return_tensors = 'pt',
        truncation=True,
        padding=True
    )

    #the output must match the required format of a model
    output = {
        'input_ids': encoding['input_ids'].flatten(),
        'attention_mask': encoding['attention_mask'].flatten(),
        'targets': torch.tensor(target, dtype=torch.long)
    }

    if self.include_raw_text:
      output['text'] =  question

    return output

#collator is to stack data with different length in this case
#without the collator, DataLoader can't batch 2 sentences with diff length
collator = DataCollatorWithPadding(tokenizer=tokenizer_obj, padding='longest')

def create_data_loader(df, tokenizer, max_len, batch_size, include_raw_text=False):
  ds = PairDataset(
      questions = df.Question.to_list(),
      targets = df.Label.to_list(),
      tokenizer = tokenizer,
      max_len = max_len,
      include_raw_text = include_raw_text
  )
  return DataLoader(ds, batch_size=batch_size, collate_fn=collator)
  #return DataLoader(ds, batch_size=batch_size)

MAX_LEN = 512
BATCH_SIZE = 4


train_dataloader = create_data_loader(df_train, tokenizer_obj, MAX_LEN, BATCH_SIZE)

test_dataloader = create_data_loader(df_test, tokenizer_obj, MAX_LEN, BATCH_SIZE)

val_dataloader = create_data_loader(df_val, tokenizer_obj, MAX_LEN, BATCH_SIZE)

"""#Model Classifier Architecture"""

class Classifier(nn.Module):
  def __init__(self, n_classes):
    super(Classifier, self).__init__()
    self.bert = BertModel.from_pretrained("bert-base-uncased", return_dict=False)
    self.drop = nn.Dropout(p=0.3)
    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)

  def forward(self, input_ids, attention_mask):
    _, pooled_output = self.bert(
        input_ids = input_ids,
        attention_mask = attention_mask
    )

    output = self.drop(pooled_output)
    return self.out(output)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

model = Classifier(3)
model = model.to(device)

def train_model(model, dataloader, loss_fn, optimizer, device, scheduler, n_example):
  model = model.train()
  losses = []
  correct_pred = 0

  for d in dataloader:
    input_ids = d['input_ids'].to(device)
    attention_mask = d['attention_mask'].to(device)
    targets = d['targets'].to(device)


    outputs = model(input_ids = input_ids, attention_mask = attention_mask)
    _,preds = torch.max(outputs, dim=1)
    loss = loss_fn(outputs, targets)


    correct_pred += torch.sum(preds == targets).cpu()

    losses.append(loss.item())

    loss.backward()


    #gradient clipping, ensuring that exploding/imploding gradient is mitigated

    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

    optimizer.step()

    scheduler.step()

    optimizer.zero_grad()


  return correct_pred/n_example, np.mean(losses)



def eval_model(model, dataloader, loss_fn, device,n_example):
  model = model.train()
  losses = []
  correct_pred = 0

  for d in dataloader:
    input_ids = d['input_ids'].to(device)
    attention_mask = d['attention_mask'].to(device)
    targets = d['targets'].to(device)


    outputs = model(input_ids = input_ids, attention_mask = attention_mask)
    _,preds = torch.max(outputs, dim=1)
    loss = loss_fn(outputs, targets)


    correct_pred += torch.sum(preds == targets).cpu()

    losses.append(loss.item())


  return correct_pred/n_example, np.mean(losses)

"""#Training"""

torch.cuda.empty_cache()

EPOCH = 100
optimizer = optim.AdamW(model.parameters(), lr=1e-5)

total_step = len(train_dataloader) * EPOCH

scheduler = get_linear_schedule_with_warmup(
    optimizer,
    num_warmup_steps = 0,
    num_training_steps = total_step
)

loss_fn = nn.CrossEntropyLoss().to(device)


history = defaultdict(list)
best_acc = 0


for epoch in range(EPOCH):
  print(f'EPOCH {epoch + 1}/ {EPOCH}')
  train_acc, train_loss = train_model(model, train_dataloader, loss_fn, optimizer,
                                      device, scheduler, len(df_train))

  val_acc, val_loss = eval_model(model, test_dataloader, loss_fn,
                                 device, len(df_test))

  history['train_acc'].append(train_acc)
  history['train_loss'].append(train_loss)
  history['val_acc'].append(val_acc)
  history['val_loss'].append(val_loss)

  if val_acc > best_acc:
    
    torch.save(model.state_dict(), f'{PATH}/{torch.round(val_acc, decimals=0)*100}_weight.pth')
    best_acc = val_acc


print(f"\n{line} Best accuracy for the test set = {best_acc} {line}\n")

"""#Baseline

"""
X_train = df_train.Question.to_list()
y_train = df_train.Label.to_list()
X_test = df_test.Question.to_list()
y_test = df_test.Label.to_list()

def get_baseline_avg(n, strat):

  clf = DummyClassifier(strategy=strat)

  total_acc = []

  for i in range(n):

    clf.fit(X_train, y_train)

    dummy_y_pred = clf.predict(X_test)

    cr = classification_report(y_test, dummy_y_pred, output_dict=True)

    acc = cr['accuracy']

    total_acc.append(acc)



  return np.mean(total_acc)

fig, ax = plt.subplots()

cmap = plt.get_cmap('viridis')
colors = [cmap(i) for i in np.linspace(0, 1, len(df.Label.value_counts()))]

df.Label.value_counts().plot(kind='barh', color=colors, ax=ax)

plt.ylabel("Label")
plt.xlabel("Count")
plt.title("Data Visualization")

"""##Baseline - Stratified Guess"""

#guessing the label based on stratified, expected answer would be in the range of
#30 - 50%
stratified = get_baseline_avg(100, "stratified")

print(f"\n{line}Stratified baseline = {stratified}{line}\n")

"""##Baseline - Most Frequent Label Guess"""

#silencing the UndefinedMetricWarning because guessing the most frequent label
#all the time will result in 0 precision and recall, which results in an error
#in the calculation of F1 Score


#expected answer would be approximately 50%
most_frequent = get_baseline_avg(100, "most_frequent")


print(f"\n{line}Most_frequent baseline = {most_frequent}{line}\n")

"""#Evaluation"""

def get_predictions(model, data_loader):
  model = model.eval()
  #raw_text = []
  predictions = []
  prediction_probs = []
  real_val = []

  with torch.no_grad():
    for d in data_loader:
      #text = d['text']
      input_ids = d['input_ids'].to(device)
      attention_mask = d['attention_mask'].to(device)
      targets = d['targets'].to(device)


      outputs = model(input_ids=input_ids, attention_mask=attention_mask)
      _, preds = torch.max(outputs, dim=1)

      prob = F.softmax(outputs, dim=1)

      #raw_text.exted(text)
      predictions.extend(preds)
      prediction_probs.extend(prob)
      real_val.extend(targets)

  predictions = torch.stack(predictions).cpu()
  prediction_probs = torch.stack(prediction_probs).cpu()
  real_val = torch.stack(real_val).cpu()


  return predictions, prediction_probs, real_val

#plotting confusion matrix
def show_confusion_matrix(cm):
  hmap = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')
  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')
  plt.ylabel('True Label')
  plt.xlabel('Predicted Label')



#validating on the test-set, model hasnt seen this data before
val_pred, val_pred_prob, val_test = get_predictions(model, val_dataloader)

cm = confusion_matrix(val_test, val_pred)

df_cm = pd.DataFrame(cm)

print(f"\n{line}SHOWING CONFUSION MATRIX{line}\n")
show_confusion_matrix(df_cm)

print(f"\n{line}CLASSIFICATION REPORT{line}\n")
print(classification_report(val_test, val_pred))

"""#Inference

"""

def infer_on_text(text, model, tokenizer):

  encoded = tokenizer.encode_plus(text,
                                  max_length=512,
                                  add_special_tokens=True,
                                  return_token_type_ids=False,
                                  pad_to_max_length=True,
                                  return_attention_mask=True,
                                  truncation=True,
                                  return_tensors='pt')

  input_ids = encoded['input_ids'].to(device)
  attention_mask = encoded['attention_mask'].to(device)

  output = model(input_ids, attention_mask)

  probs = torch.nn.functional.softmax(output, dim=1)

  _, preds = torch.max(output, dim=1)

  pred_label = preds[0]
  print(f"Prediction: {pred_label} with confidence of {probs[0][pred_label]}")


text = "[CLS]Should the United States ban civilian ownership of assault weapons and high-capacity magazines?[SEP] absolutely yes"

print(f"{line}TESTING INFERENCE{line}")
print(text)
print('\n')
infer_on_text(text, model, tokenizer_obj)
print('\n\n')



